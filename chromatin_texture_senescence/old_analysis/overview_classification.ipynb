{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.decomposition import PCA\n",
    "# from openTSNE import TSNE as oTSNE\n",
    "# from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 1) read both texture and other feature tables, join\n",
    "\n",
    "csv_feats_texture = '/scratch/hoerl/20230507_imr90_stitching/20230507_imr90_ov_stitch_output/segmentation_cellpose_maxproj_d70_ft07/texture_feats.csv'\n",
    "# csv_feats_texture = '/scratch/hoerl/20230507_imr90_stitching/20230507_imr90_ov_stitch_output/segmentation_cellpose_maxproj_d70_ft07/texture_feats_normalized_per_cell.csv'\n",
    "csv_feats_other = '/scratch/hoerl/20230507_imr90_stitching/20230507_imr90_ov_stitch_output/segmentation_cellpose_maxproj_d70_ft07/other_feats.csv'\n",
    "\n",
    "df = pd.read_csv(csv_feats_texture).set_index(['file', 'label'])\n",
    "df = df.merge(pd.read_csv(csv_feats_other), on=['file', 'label'])\n",
    "\n",
    "df['file_stem'] = df.reset_index().file.apply(lambda f: Path(f).stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_overview_csv = '/scratch/hoerl/auto_sir_experiment_overview.csv'\n",
    "df_exp_overview = pd.read_csv(exp_overview_csv, sep=';')[['file', 'treatment', 'replicate_technical', 'replicate_biological']]\n",
    "df_exp_overview['replicate_technical'] = df_exp_overview['replicate_technical'].apply(str)\n",
    "df_exp_overview['replicate_biological'] = df_exp_overview['replicate_biological'].apply(str)\n",
    "\n",
    "# df = df.set_index(['file_stem'])\n",
    "df = df.merge(df_exp_overview, left_on='file_stem', right_on='file', suffixes=(None, '_duplicate') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set as index again\n",
    "df = df.set_index(['file', 'label'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.replicate_biological == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) prepare features\n",
    "\n",
    "# get all columns that start with 'tex' --> texture features\n",
    "tex_values = df[[c for c in df.columns if c.startswith('tex')] + ['other_mean_intensity', 'other_area', 'other_eccentricity']].values\n",
    "\n",
    "# we have NaNs -> impute\n",
    "# probably not necessary here, but copied from above anyway\n",
    "tex_values = SimpleImputer().fit_transform(tex_values)\n",
    "\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "tex_values = scaler.fit_transform(tex_values)\n",
    "\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "ys = le.fit_transform(df.treatment)\n",
    "\n",
    "# make one-hot encoded ys for OvR classification\n",
    "binarizer = LabelBinarizer()\n",
    "onehot_y = binarizer.fit_transform(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold, LeaveOneGroupOut\n",
    "\n",
    "figsize = (8, 8)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "cls = SVC(C=100, probability=True)\n",
    "\n",
    "\n",
    "cv_strategies = (\n",
    "    (StratifiedKFold(10, shuffle=True), None, '10-Fold Stratified CV'),\n",
    "    (LeaveOneGroupOut(), [c + '_' + r1 + '_' + r2 for c, r1, r2 in zip(df.treatment, df.replicate_biological, df.replicate_technical)], 'Leave-One-Replicate-Out (Technical)'),\n",
    "    (LeaveOneGroupOut(), [c + '_' + r for c,r in zip(df.treatment, df.replicate_biological)], 'Leave-One-Replicate-Out (Biological)')\n",
    ")\n",
    "\n",
    "for cv, groups, desc in cv_strategies:\n",
    "    cv.split(tex_values, ys, groups)\n",
    "\n",
    "    prob_pred = cross_val_predict(cls, tex_values, ys, cv=cv, groups=groups, n_jobs=-1, method='predict_proba')\n",
    "    pred = np.argmax(prob_pred, axis=1)\n",
    "\n",
    "    # we have only 2 classes -> use probabilities for class 1 for further analysis\n",
    "    if prob_pred.shape[1] == 2:\n",
    "        prob_pred = prob_pred[:,1:2] # 1-column selection\n",
    "\n",
    "    # get accuracy, AP & PR curve\n",
    "    overall_acc = (pred == ys).sum() / len(ys)\n",
    "    pr, re, _ = precision_recall_curve(onehot_y.ravel(), prob_pred.ravel())\n",
    "    ap = average_precision_score(onehot_y.ravel(), prob_pred.ravel())\n",
    "\n",
    "    ax.plot(re, pr, label=f'{desc}\\naccuracy={overall_acc:.3f}\\nAP={ap:.3f}', lw=2)\n",
    "\n",
    "# add \"random guess\" baseline to all plots\n",
    "_, cts = np.unique(ys, return_counts=True)\n",
    "baseline_pr = np.mean(cts/len(ys))\n",
    "\n",
    "ax.plot([0, 1], [baseline_pr, baseline_pr], linestyle='dashed', color='firebrick', lw=2, label='random guess')\n",
    "    \n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel('Precision')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cross-val prediction and string labels\n",
    "\n",
    "cv, groups, _ = cv_strategies[0]\n",
    "\n",
    "pred = cross_val_predict(cls, tex_values, ys, cv=cv, n_jobs=-1, groups=groups)\n",
    "labs_pred = le.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = defaultdict(lambda : np.zeros(np.max(ys) + 1))\n",
    "\n",
    "# replicates_ = replicates\n",
    "# replicates_ = df.replicate_biological\n",
    "replicates_ = df.replicate_technical\n",
    "\n",
    "# go through all predictions, increment corresponding row\n",
    "for cond, repl, lab_pred in zip(df.treatment, replicates_, labs_pred):\n",
    "    conf_mat[(cond, repl)][le.transform([lab_pred])[0]] += 1\n",
    "\n",
    "# get sorted label + number of samples\n",
    "input_cls = [s[0] + (f'N: {int(s[1].sum())}' ,) for s in sorted(conf_mat.items())]\n",
    "\n",
    "# make matrix from dict, normalize per-row\n",
    "mat = np.array([s[1] for s in sorted(conf_mat.items())])\n",
    "mat = mat / np.sum(mat, axis=1).reshape((-1,1))\n",
    "\n",
    "# plot as heatmap\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(mat, cmap='Blues', aspect=0.2)\n",
    "plt.yticks(ticks=np.arange(len(input_cls)), labels=[', '.join(c) for c in input_cls]);\n",
    "plt.xticks(ticks=np.arange(np.max(ys) + 1), labels=le.inverse_transform(np.arange(np.max(ys) + 1)), rotation='vertical');\n",
    "\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.colorbar(shrink=.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
