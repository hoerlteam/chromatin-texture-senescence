{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "h5file = '/data/cooperation_data/Preliminary_projects/AgyrisPapantonis_ChromatinTexture_AgeingCells/auto_sir_ageing-cells/20201208_IMR90_3day/rep1/3f2f7d32d280ce05293143834aa15a08.h5'\n",
    "out_h5file = '/scratch/hoerl/compression_test.h5'\n",
    "\n",
    "\n",
    "def create_compressed_h5_copy(h5_file_in, h5_file_out, compression_level=4, force=False):\n",
    "    \n",
    "    # warn if we try to overwrite output file\n",
    "    if os.path.exists(h5_file_out) and not force:\n",
    "        raise ValueError('Target file {} exists.'.format(h5_file_out))\n",
    "\n",
    "    with h5.File(h5_file_in, 'r') as fd_in:\n",
    "        with h5.File(h5_file_out, 'w') as fd_out:\n",
    "\n",
    "            # copy attributes\n",
    "            # NB: need to use AttributeManager, otherwise it complains about data types?\n",
    "            am = h5.AttributeManager(fd_out)\n",
    "            for (k,v) in fd_in.attrs.items():\n",
    "                am[k] = v\n",
    "\n",
    "            # dfs copy\n",
    "            keys = list(fd_in.keys())\n",
    "            while len(keys) > 0:\n",
    "\n",
    "                k = keys.pop()\n",
    "\n",
    "                # we arrived at a dataset -> copy compressed\n",
    "                if isinstance(fd_in[k], h5.Dataset):\n",
    "                    # TODO: check if dtype specification is necessary\n",
    "                    fd_out.create_dataset(k, data=fd_in[k], shuffle=True, compression='gzip', compression_opts=compression_level)\n",
    "                # we are at a datset\n",
    "                else:\n",
    "                    fd_out.create_group(k)\n",
    "                    # add children to working list\n",
    "                    keys.extend(map(lambda ki: '{}/{}'.format(k,ki), fd_in[k].keys()))\n",
    "\n",
    "                am = h5.AttributeManager(fd_out[k])\n",
    "                for (ke,v) in fd_in[k].attrs.items():\n",
    "                    am[ke] = v\n",
    "    \n",
    "# create_compressed_h5_copy(h5file, out_h5file, compression_level=4, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import add\n",
    "\n",
    "# root = '/data/cooperation_data/Preliminary_projects/AgyrisPapantonis_ChromatinTexture_AgeingCells/auto_sir_ageing-cells/'\n",
    "root = '/data/cooperation_data/ArgyrisPapantonis-nuclear_architecture/Simona_Nasiscionyte/STED'\n",
    "\n",
    "# datasets = ['20201214_IMR90_9day', '20201208_IMR90_3day', '2020622_IMR90_untreated_old',\n",
    "#             '2020625_IMR90_3d_ICM_young', '2020629_IMR90_6d_ICM_young', '2020702_IMR90_9d_ICM_young',\n",
    "#            '2020705_IMR90_young_untreated', '20210326_IMR90_young_untr', '20210402_IMR90_old']\n",
    "\n",
    "datasets = ['20220107_IMR90_young', '20220111_IMR90_old']\n",
    "\n",
    "h5_files = reduce(add, [glob.glob(os.path.join(root, d, '*', '*.h5')) for d in datasets])\n",
    "# h5_files = reduce(add, [glob.glob(os.path.join(root, d, '*', '*', '*.h5')) for d in datasets])\n",
    "# h5_files = reduce(add, [glob.glob(os.path.join(root, d, '*', '*.h5')) for d in datasets])\n",
    "h5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "out_dir = '/scratch/hoerl/auto_sir_dna_comp'\n",
    "\n",
    "for h5file in h5_files:\n",
    "    outfile = h5file.replace(root, out_dir)\n",
    "    d, _ = os.path.split(outfile)\n",
    "    \n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "    \n",
    "    try:\n",
    "        create_compressed_h5_copy(h5file, outfile)\n",
    "    except ValueError as e:\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
