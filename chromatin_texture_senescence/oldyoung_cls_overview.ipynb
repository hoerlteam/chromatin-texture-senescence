{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "## 1) read both texture and other feature tables, join\n",
    "\n",
    "# NOTE: select global norm texture feats or per cell normalized\n",
    "# csv_feats_texture = '/Users/david/Desktop/IMR90_30112022/segmentation_cellpose_d120_ft06/texture_feats.csv'\n",
    "# csv_feats_texture = '/Users/david/Desktop/IMR90_30112022/segmentation_cellpose_d120_ft06/texture_feats_normalized_per_cell.csv'\n",
    "# csv_feats_other = '/Users/david/Desktop/IMR90_30112022/segmentation_cellpose_d120_ft06/other_feats.csv'\n",
    "\n",
    "csv_feats_texture = '/scratch/hoerl/20230507_imr90_stitching/20230507_imr90_ov_stitch_output/segmentation_cellpose_maxproj_d70_ft07/texture_feats.csv'\n",
    "# csv_feats_texture = '/scratch/hoerl/20230507_imr90_stitching/20230507_imr90_ov_stitch_output/segmentation_cellpose_maxproj_d70_ft07/texture_feats_normalized_per_cell.csv'\n",
    "csv_feats_other = '/scratch/hoerl/20230507_imr90_stitching/20230507_imr90_ov_stitch_output/segmentation_cellpose_maxproj_d70_ft07/other_feats.csv'\n",
    "\n",
    "df = pd.read_csv(csv_feats_texture).set_index(['file', 'label'])\n",
    "df = df.merge(pd.read_csv(csv_feats_other), on=['file', 'label'])\n",
    "\n",
    "df['file_stem'] = df.reset_index().file.apply(lambda f: Path(f).stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_overview_csv = '/scratch/hoerl/auto_sir_experiment_overview.csv'\n",
    "\n",
    "df_exp_overview = pd.read_csv(exp_overview_csv, sep=';')[['file', 'treatment', 'replicate_technical', 'replicate_biological', 'overlapping_tiles']]\n",
    "df_exp_overview['replicate_technical'] = df_exp_overview['replicate_technical'].apply(str)\n",
    "df_exp_overview['replicate_biological'] = df_exp_overview['replicate_biological'].apply(str)\n",
    "\n",
    "df = df.merge(df_exp_overview, left_on='file_stem', right_on='file', suffixes=(None, '_duplicate') )\n",
    "\n",
    "# remove non-overlapping overviews (run 3f2f7d32d280ce05293143834aa15a08)\n",
    "df = df[df.overlapping_tiles]\n",
    "\n",
    "# set as index again\n",
    "df = df.set_index(['file', 'label'])\n",
    "\n",
    "# only use single replicate\n",
    "# df = df[df['replicate_biological'] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldyoung_classes = ['young', 'old']\n",
    "\n",
    "df_oldyoung = df[df.treatment.isin(oldyoung_classes)]\n",
    "df_treated = df[~df.treatment.isin(oldyoung_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) prepare features\n",
    "\n",
    "# get all columns that start with 'tex' --> texture features\n",
    "# plus mean intensity, area, eccentricity\n",
    "feature_cols = [c for c in df.columns if c.startswith('tex')] + ['other_mean_intensity', 'other_area', 'other_eccentricity']\n",
    "\n",
    "tex_values_oldyoung = df_oldyoung[feature_cols].values\n",
    "tex_values_treated = df_treated[feature_cols].values\n",
    "\n",
    "# we have NaNs -> impute\n",
    "# probably not necessary here, but copied from above anyway\n",
    "tex_values_oldyoung = SimpleImputer().fit_transform(tex_values_oldyoung)\n",
    "tex_values_treated = SimpleImputer().fit_transform(tex_values_treated)\n",
    "\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "tex_values_oldyoung = scaler.fit_transform(tex_values_oldyoung)\n",
    "tex_values_treated = scaler.transform(tex_values_treated)\n",
    "\n",
    "le_oldyoung = LabelEncoder()\n",
    "y_oldyoung = le_oldyoung.fit_transform(df_oldyoung.treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC, C<1 -> stronger regularization as default\n",
    "cls = SVC(C=0.1, probability=True, class_weight='balanced')\n",
    "\n",
    "# cls = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "\n",
    "# CV scoring to assess classifier performance on old/young\n",
    "cv = StratifiedKFold(5, shuffle=True)\n",
    "y_oldyoung_pred = cross_val_predict(cls, tex_values_oldyoung, y_oldyoung, n_jobs=-1, cv=cv)\n",
    "np.mean(y_oldyoung_pred == y_oldyoung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit again on whole old/young dataset\n",
    "cls.fit(tex_values_oldyoung, y_oldyoung);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "young_old_indices = le_oldyoung.transform(oldyoung_classes)\n",
    "young_old_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treated_pred = cls.predict_proba(tex_values_treated)\n",
    "\n",
    "df_pred = pd.DataFrame()\n",
    "\n",
    "df_pred['cell_class'] = df_treated.treatment\n",
    "df_pred['replicate_bio'] = df_treated.replicate_biological\n",
    "df_pred['replicate_tech'] = df_treated.replicate_technical\n",
    "\n",
    "df_pred['prob_young'] = y_treated_pred.T[young_old_indices[0]]\n",
    "df_pred['prob_old'] = y_treated_pred.T[young_old_indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "## group by technical or biological replicates\n",
    "# df_grouped = df_pred.groupby(['cell_class', 'replicate_tech'])[['prob_young', 'prob_old']]\n",
    "df_grouped = df_pred.groupby(['cell_class', 'replicate_bio'])[['prob_young', 'prob_old']]\n",
    "\n",
    "# average prediction per group\n",
    "df_confmat = df_grouped.mean()\n",
    "\n",
    "# add replicate size to index -> for labelling in plot\n",
    "df_confmat['count'] = list(map(lambda c: f'N={c}', df_grouped.count().iloc[:,0].values))\n",
    "df_confmat = df_confmat.set_index('count', append=True)\n",
    "\n",
    "plt.figure(figsize=(6,8))\n",
    "sns.heatmap(df_confmat, cmap='Blues', annot=True, vmin=0, vmax=1)\n",
    "plt.yticks(ticks=range(len(df_confmat)), labels=map(', '.join, df_confmat.index))\n",
    "# plt.xticks(ticks=range(len(oldyoung_classes)), labels=oldyoung_classes, rotation='vertical');\n",
    "plt.xticks(ticks=range(len(oldyoung_classes)), labels=oldyoung_classes);\n",
    "\n",
    "# save\n",
    "plt.rc('pdf', fonttype='42')\n",
    "plt.savefig('/home/hoerl/ageing_dna_texture_figure_parts/confusionmatrix_oldyoung-classification_confocal.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confmat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
