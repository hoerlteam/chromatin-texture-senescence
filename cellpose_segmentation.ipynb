{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c301965-9eaf-4fa1-940b-4410011a76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py as h5\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import rescale\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import torch\n",
    "from cellpose.models import Cellpose\n",
    "from cellpose import dynamics\n",
    "\n",
    "from scipy.ndimage.filters import maximum_filter1d\n",
    "import fastremap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9950919-4349-4d39-8833-8c901040d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_patch_large_cell = False\n",
    "\n",
    "def get_masks(p, iscell=None, rpad=20):\n",
    "    \"\"\" create masks using pixel convergence after running dynamics\n",
    "    \n",
    "    Makes a histogram of final pixel locations p, initializes masks \n",
    "    at peaks of histogram and extends the masks from the peaks so that\n",
    "    they include all pixels with more than 2 final pixels p. Discards \n",
    "    masks with flow errors greater than the threshold. \n",
    "    Parameters\n",
    "    ----------------\n",
    "    p: float32, 3D or 4D array\n",
    "        final locations of each pixel after dynamics,\n",
    "        size [axis x Ly x Lx] or [axis x Lz x Ly x Lx].\n",
    "    iscell: bool, 2D or 3D array\n",
    "        if iscell is not None, set pixels that are \n",
    "        iscell False to stay in their original location.\n",
    "    rpad: int (optional, default 20)\n",
    "        histogram edge padding\n",
    "    threshold: float (optional, default 0.4)\n",
    "        masks with flow error greater than threshold are discarded \n",
    "        (if flows is not None)\n",
    "    flows: float, 3D or 4D array (optional, default None)\n",
    "        flows [axis x Ly x Lx] or [axis x Lz x Ly x Lx]. If flows\n",
    "        is not None, then masks with inconsistent flows are removed using \n",
    "        `remove_bad_flow_masks`.\n",
    "    Returns\n",
    "    ---------------\n",
    "    M0: int, 2D or 3D array\n",
    "        masks with inconsistent flow masks removed, \n",
    "        0=NO masks; 1,2,...=mask labels,\n",
    "        size [Ly x Lx] or [Lz x Ly x Lx]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pflows = []\n",
    "    edges = []\n",
    "    shape0 = p.shape[1:]\n",
    "    dims = len(p)\n",
    "    if iscell is not None:\n",
    "        if dims==3:\n",
    "            inds = np.meshgrid(np.arange(shape0[0]), np.arange(shape0[1]),\n",
    "                np.arange(shape0[2]), indexing='ij')\n",
    "        elif dims==2:\n",
    "            inds = np.meshgrid(np.arange(shape0[0]), np.arange(shape0[1]),\n",
    "                     indexing='ij')\n",
    "        for i in range(dims):\n",
    "            p[i, ~iscell] = inds[i][~iscell]\n",
    "\n",
    "    for i in range(dims):\n",
    "        pflows.append(p[i].flatten().astype('int32'))\n",
    "        edges.append(np.arange(-.5-rpad, shape0[i]+.5+rpad, 1))\n",
    "\n",
    "    h,_ = np.histogramdd(tuple(pflows), bins=edges)\n",
    "    hmax = h.copy()\n",
    "    for i in range(dims):\n",
    "        hmax = maximum_filter1d(hmax, 5, axis=i)\n",
    "\n",
    "    seeds = np.nonzero(np.logical_and(h-hmax>-1e-6, h>10))\n",
    "    Nmax = h[seeds]\n",
    "    isort = np.argsort(Nmax)[::-1]\n",
    "    for s in seeds:\n",
    "        s = s[isort]\n",
    "\n",
    "    pix = list(np.array(seeds).T)\n",
    "\n",
    "    shape = h.shape\n",
    "    if dims==3:\n",
    "        expand = np.nonzero(np.ones((3,3,3)))\n",
    "    else:\n",
    "        expand = np.nonzero(np.ones((3,3)))\n",
    "    for e in expand:\n",
    "        e = np.expand_dims(e,1)\n",
    "\n",
    "    for iter in range(5):\n",
    "        for k in range(len(pix)):\n",
    "            if iter==0:\n",
    "                pix[k] = list(pix[k])\n",
    "            newpix = []\n",
    "            iin = []\n",
    "            for i,e in enumerate(expand):\n",
    "                epix = e[:,np.newaxis] + np.expand_dims(pix[k][i], 0) - 1\n",
    "                epix = epix.flatten()\n",
    "                iin.append(np.logical_and(epix>=0, epix<shape[i]))\n",
    "                newpix.append(epix)\n",
    "            iin = np.all(tuple(iin), axis=0)\n",
    "            for p in newpix:\n",
    "                p = p[iin]\n",
    "            newpix = tuple(newpix)\n",
    "            igood = h[newpix]>2\n",
    "            for i in range(dims):\n",
    "                pix[k][i] = newpix[i][igood]\n",
    "            if iter==4:\n",
    "                pix[k] = tuple(pix[k])\n",
    "    \n",
    "    M = np.zeros(h.shape, np.uint32)\n",
    "    for k in range(len(pix)):\n",
    "        M[pix[k]] = 1+k\n",
    "        \n",
    "    for i in range(dims):\n",
    "        pflows[i] = pflows[i] + rpad\n",
    "    M0 = M[tuple(pflows)]\n",
    "\n",
    "    # NB: commented out to remove hardcoded 40% image size max cell size filter\n",
    "    # remove big masks\n",
    "#     uniq, counts = fastremap.unique(M0, return_counts=True)\n",
    "#     big = np.prod(shape0) * 0.4\n",
    "#     bigc = uniq[counts > big]\n",
    "#     if len(bigc) > 0 and (len(bigc)>1 or bigc[0]!=0):\n",
    "#         M0 = fastremap.mask(M0, bigc)\n",
    "    \n",
    "    fastremap.renumber(M0, in_place=True) #convenient to guarantee non-skipped labels\n",
    "    M0 = np.reshape(M0, shape0)\n",
    "    return M0\n",
    "\n",
    "# monkey-patch if desired\n",
    "if monkey_patch_large_cell:\n",
    "    dynamics.get_masks = get_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04fb1b-2774-4a68-b519-9b343f255429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_details(in_file, normalize=True, percentiles=(2.5, 99.5)):\n",
    "    imgs = []\n",
    "    percentiles_ = []\n",
    "    names = []\n",
    "    \n",
    "    with h5.File(in_file, 'r') as fd:\n",
    "        details = [k for k in fd['experiment'].keys() if 'detail' in k]\n",
    "\n",
    "        for detail_name in details:\n",
    "            data = fd['experiment/{}/0/0'.format(detail_name)][...]\n",
    "            \n",
    "            # rescale intensity\n",
    "            percentile = tuple(np.percentile(data, percentiles))\n",
    "            \n",
    "            if normalize:\n",
    "                data = rescale_intensity(data, percentile, 'uint8').astype(np.uint8)\n",
    "            \n",
    "            imgs.append(data)\n",
    "            percentiles_.append(percentile) # save percentiles in raw intensity\n",
    "            names.append(detail_name) # save dataset name\n",
    "            \n",
    "    return imgs, percentiles_, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188060a7-75ce-45db-a1f1-e3711c1b1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_files = glob.glob('/scratch/hoerl/auto_sir_dna_comp/20207*/*/*.h5')\n",
    "in_files.sort()\n",
    "\n",
    "in_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e704839-7d78-4186-bdf3-8ecc5d8c4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_details(in_file, normalize=True, percentiles=(2.5, 99.5)):\n",
    "    imgs = []\n",
    "    percentiles_ = []\n",
    "    names = []\n",
    "    \n",
    "    with h5.File(in_file, 'r') as fd:\n",
    "        details = [k for k in fd['experiment'].keys() if 'detail' in k]\n",
    "\n",
    "        for detail_name in details:\n",
    "            data = fd['experiment/{}/0/0'.format(detail_name)][...]\n",
    "            \n",
    "            # rescale intensity\n",
    "            percentile = tuple(np.percentile(data, percentiles))\n",
    "            \n",
    "            if normalize:\n",
    "                data = rescale_intensity(data, percentile, 'uint8').astype(np.uint8)\n",
    "            \n",
    "            imgs.append(data)\n",
    "            percentiles_.append(percentile) # save percentiles in raw intensity\n",
    "            names.append(detail_name) # save dataset name\n",
    "            \n",
    "    return imgs, percentiles_, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77906785-156b-42d1-9bd8-fe2d29ebceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# percentiles for normalization\n",
    "percentiles=(2.5, 99.8)\n",
    "# whether to normalize per replicate (True) or per image (False)\n",
    "normalize_per_replicate = True\n",
    "\n",
    "# single-threaded version:\n",
    "# loaded = {f: load_all_details(f) for f in in_files}\n",
    "\n",
    "loaded = {}\n",
    "with ThreadPoolExecutor() as tpe:\n",
    "    futures = [tpe.submit(load_all_details, f, not normalize_per_replicate, percentiles) for f in in_files]\n",
    "    for i, (f,future) in enumerate(zip(in_files, futures)):\n",
    "        loaded[f] = future.result()    \n",
    "        print(f'({i+1}/{len(futures)}): {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98acf8-9fc5-485b-bd81-949047f9bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgs, percs, names = next(iter(loaded.values()))\n",
    "\n",
    "idx = min(2, len(imgs)-1)\n",
    "img = gaussian_filter(imgs[idx].squeeze().astype(np.float32), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19816293-882f-44c8-9c6a-cce4eaa1cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cellpose(model_type='nuclei', net_avg=True, device=torch.device('cuda:0'))\n",
    "masks, flows, styles, diams = model.eval([img], channels=[0,0], rescale=False, diameter=500, normalize=True, flow_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc84509-610a-4487-b4e7-b33cdeb217ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
    "axs[0].imshow(img.squeeze(), cmap='gray')\n",
    "axs[1].imshow(masks[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa3a74-cd3c-42c9-8ed9-a4ca9fb5a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_imgs_to_test = min(len(imgs), 10)\n",
    "test_imgs = random.sample(imgs, n_imgs_to_test)\n",
    "test_imgs = [gaussian_filter(img.squeeze().astype(np.float32), 5) for img in test_imgs]\n",
    "\n",
    "masks, _, _, _ = model.eval(test_imgs, channels=[0,0], rescale=False, diameter=1000, normalize=True, flow_threshold=0.4, cellprob_threshold=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431ea60-1460-4502-b878-2bd1598bad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in zip(test_imgs, masks):\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
    "    axs[0].imshow(img.squeeze(), cmap='gray')\n",
    "    axs[1].imshow(mask.squeeze(), interpolation='nearest')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be7618c9-a807-4a7f-b0fc-7ec4db8f129b",
   "metadata": {},
   "source": [
    "## Use Cellpose to segment large images\n",
    "\n",
    "E.g. spinning disk data, stitched overviews, .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16d807ba-fcc4-4f57-9530-4b2a8ac60129",
   "metadata": {},
   "source": [
    "### get list of files to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e8ffab-5f6c-4d3d-8a30-e840aa8f19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from nd2reader import ND2Reader\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "# new DAPI-stained (ctrl) IMR90 (Dec 2022)\n",
    "# files = glob.glob('/data/cooperation_data/ArgyrisPapantonis-nuclear_architecture/Hartmann_Harz/IMR90_30112022/*.nd2')\n",
    "\n",
    "# stitched overviews from autoSTED\n",
    "files = glob.glob('/scratch/hoerl/20230507_imr90_stitching/20230507_imr90_ov_stitch_output/*.tif')\n",
    "\n",
    "files = sorted(files)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: only loads single plane images at the moment\n",
    "\n",
    "imgs = []\n",
    "for file in files:\n",
    "    with ND2Reader(file) as reader:\n",
    "        img = np.array(reader[0])\n",
    "    print(f'loaded {file}')\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for file in files:\n",
    "    imgs.append(imread(file))\n",
    "    print(f'loaded {file}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c7eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max project in z\n",
    "imgs = [img.max(axis=0) for img in imgs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58bdf7f3-375e-46db-9ea6-8edaa98b3a0a",
   "metadata": {},
   "source": [
    "### CLAHE to increase contrast before segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93d3db-543c-4995-b1ef-23e2873ebca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_adapthist\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "idx  = 12\n",
    "img = imgs[idx]\n",
    "\n",
    "img_clahe = equalize_adapthist(img, kernel_size=100, clip_limit=0.005)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "axs[0].imshow(img, cmap='gray')\n",
    "axs[1].imshow(img_clahe, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_clahe = []\n",
    "\n",
    "for idx in range(len(imgs)):\n",
    "    \n",
    "    # do CLAHE\n",
    "    img_clahe = equalize_adapthist(imgs[idx], kernel_size=500, clip_limit=0.02)\n",
    "    \n",
    "    # keep black borders at exactly 0\n",
    "    # TODO: really necessary?\n",
    "    img_clahe[imgs[idx] == 0] = 0\n",
    "    \n",
    "    imgs_clahe.append(img_clahe)\n",
    "    \n",
    "    print(f'CLAHE on {files[idx]} done.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bde7f13-3eab-4ca6-a8ba-1112ee48e34a",
   "metadata": {},
   "source": [
    "### segment with Cellpose\n",
    "\n",
    "Verdict: work reasonably well, CLAHE sometimes helps, some cells omitted, so maybe refine Cellpose parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c4fef-8c88-44d0-a9a1-da0ac8342f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "diam = 70\n",
    "flow_thresh = 0.7\n",
    "\n",
    "idx = 35\n",
    "img = imgs[idx]\n",
    "\n",
    "dev = torch.device('cuda:1')\n",
    "model = Cellpose(model_type='nuclei', net_avg=True, device=dev)\n",
    "\n",
    "(mask,), _, _, _ = model.eval([img], channels=[0,0], diameter=diam, flow_threshold=flow_thresh)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "axs[0].imshow(img, cmap='gray')\n",
    "axs[1].imshow(mask, cmap='prism', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4bd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diam = 70\n",
    "flow_thresh = 0.7\n",
    "\n",
    "masks = []\n",
    "\n",
    "for img, file in zip(imgs, files):\n",
    "    # TODO: maybe do in one call?\n",
    "    (mask,), flows, styles, diams = model.eval([img], channels=[0,0], diameter=diam, flow_threshold=flow_thresh)\n",
    "    masks.append(mask)\n",
    "    print(f'segmented {file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de5f1a8c-c15a-4c95-82bb-e50dcd46cd40",
   "metadata": {},
   "source": [
    "### Alternative: segment with just thresholding and a bit of morphological ops\n",
    "\n",
    "Verdict: Might need more postprocessing, esp. when doing CLAHE before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93173d3-cdb7-4171-b1fe-e9df1c864875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_li\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import binary_closing, remove_small_holes, remove_small_objects, disk\n",
    "\n",
    "\n",
    "def clear_large_objects(labels, max_size, bgval=0, in_place=False):\n",
    "    \n",
    "    if not in_place:\n",
    "        labels = labels.copy()\n",
    "        \n",
    "    for rprop in regionprops(labels):\n",
    "        if rprop.area > max_size:\n",
    "            labels[rprop.slice][rprop.image] = bgval\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "hole_and_small_object_size = 500\n",
    "disk_radius = 3\n",
    "max_object_size = 500 * 500\n",
    "\n",
    "masks = []\n",
    "\n",
    "for img, file in zip(imgs, files):\n",
    "    \n",
    "    # NOTE: we calculate the threshold from pixels > 0 to ignore borders created by stitching\n",
    "    t = threshold_li(img[img>0])\n",
    "    mask = img > t\n",
    "    \n",
    "    # some morphological cleanup\n",
    "    mask = remove_small_holes(mask, hole_and_small_object_size)\n",
    "    mask = remove_small_objects(mask, hole_and_small_object_size)\n",
    "    mask = binary_closing(mask, disk(disk_radius))    \n",
    "    \n",
    "    labels = label(mask)\n",
    "    labels = clear_large_objects(labels, max_object_size)    \n",
    "    \n",
    "    masks.append(labels)\n",
    "    print(f'segmented {file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f699b03-4cd3-49ff-afb2-d45d5bf4de3c",
   "metadata": {},
   "source": [
    "### quick visualization of one image (cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9de913-9c60-47ad-bb8f-4c5d14651afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "idx = 4\n",
    "cut = (slice(0,3000), slice(0,3000))\n",
    "# clim = (0, 1200)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(12,6))\n",
    "\n",
    "axs[0].imshow(imgs[idx][cut], cmap='gray')\n",
    "axs[1].imshow(masks[idx][cut], cmap='rainbow', interpolation='nearest')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "703697fe-c027-414b-a505-891adb420c4f",
   "metadata": {},
   "source": [
    "### save masks / labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a1e52-2195-4af7-83ab-faadd77eee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tifffile import imwrite\n",
    "\n",
    "# folder name if using cellpose\n",
    "folder_name = f'segmentation_cellpose_maxproj_d{diam}_ft{str(flow_thresh).replace(\".\", \"\")}'\n",
    "# if using just thresholding\n",
    "# folder_name = 'segmentation_threshold'\n",
    "\n",
    "# make folder if necessary\n",
    "folder = (Path(files[0]).parent / folder_name)\n",
    "if not folder.exists():\n",
    "    folder.mkdir()\n",
    "\n",
    "# save masks\n",
    "for mask, file in zip(masks, files):\n",
    "    outfile = folder / (Path(file).name + '_labels.tif')\n",
    "    imwrite(outfile, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e921cdc-ebca-4dd1-a16d-fda6fa96df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that we have results in the right place\n",
    "\n",
    "!ls -l /data/cooperation_data/ArgyrisPapantonis-nuclear_architecture/Hartmann_Harz/IMR90_30112022/$folder_name/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
