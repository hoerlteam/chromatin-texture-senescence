{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2460b9d0-b79a-46b2-a578-37a72856a86c",
   "metadata": {},
   "source": [
    "# 1) load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7fe79e-1228-471b-95ca-ef611d305da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '/scratch/hoerl/auto_sir_dna_comp/20220829_glcm_good95_imagenorm.csv'\n",
    "# csv_file = '/scratch/hoerl/auto_sir_dna_comp/20220829_glcm_good95_imagenorm_confocalblur.csv'\n",
    "# csv_file = '/scratch/hoerl/auto_sir_dna_comp/20220829_glcm_good95_replicatenorm.csv'\n",
    "# csv_file = '/scratch/hoerl/auto_sir_dna_comp/20220829_glcm_good95_replicatenorm_confocalblur.csv'\n",
    "\n",
    "## CSV with experimental conditions\n",
    "exp_overview_csv = '/scratch/hoerl/auto_sir_experiment_overview.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec9ea7-e025-4c7d-9934-fffde748f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# ignore very small technical replicates (acquisition crashed/stopped bc. sample was bad)\n",
    "min_replicate_size = 10\n",
    "df = reduce(pd.DataFrame.append, [dfi for _, dfi in df.groupby(['cell_class', 'replicate']) if len(dfi)>min_replicate_size])\n",
    "\n",
    "# remove one outlying replicate (looks blurry -> air bubble/diry objective?)\n",
    "df = df[~df[['cell_class', 'replicate']].isin([('IMR90_young_untreated', '20200705_rep2')]).all(axis=1)]\n",
    "\n",
    "# get file stem for merge with standardized replicate names\n",
    "df['file_stem'] = df.filename.apply(lambda f: Path(f).stem)\n",
    "\n",
    "# read and add standardized replicate/condition info\n",
    "df_exp_overview = pd.read_csv(exp_overview_csv, sep=';')[['file', 'treatment', 'replicate_technical', 'replicate_biological', 'overlapping_tiles']]\n",
    "df_exp_overview['replicate_technical'] = df_exp_overview['replicate_technical'].apply(str)\n",
    "df_exp_overview['replicate_biological'] = df_exp_overview['replicate_biological'].apply(str)\n",
    "\n",
    "df = df.merge(df_exp_overview, left_on='file_stem', right_on='file', suffixes=(None, '_duplicate') )\n",
    "\n",
    "# auxillary columns for grouping\n",
    "df['treatment_icm_grouped'] = df.treatment.str.split('_').str[-1]\n",
    "df['replicate_biological_with_treat'] = df['treatment'] + '_' + df['replicate_biological']\n",
    "\n",
    "# cell_class for verficication\n",
    "df.cell_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee649825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional, select date range\n",
    "df = df[df.replicate.str[:6].astype(int) < 202008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48411dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ea25bf9-bd56-4bf4-ac38-d364927ee07c",
   "metadata": {},
   "source": [
    "## split old & young / ICM treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a297f-c2d3-4a03-8615-428369652f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldyoung_classes = ['IMR90_young_untreated', 'IMR90_untreated_old']\n",
    "\n",
    "df_oldyoung = df[df.cell_class.isin(oldyoung_classes)]\n",
    "df_treated = df[~df.cell_class.isin(oldyoung_classes)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b860c230-a43d-496d-9319-8aabbfe6153c",
   "metadata": {},
   "source": [
    "## feature preprocessing / numerical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce45f04-5e3a-4c82-aceb-fa6097a8426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to drop from features\n",
    "# filepaths, classes, good/bad cls & auxillariy features\n",
    "columns_to_drop = [\n",
    "                  'file', 'file_stem', 'treatment', 'replicate_technical', 'replicate_biological', 'overlapping_tiles',\n",
    "                  'dataset_name', 'filename', 'classification_manual', 'classification_auto', 'replicate',\n",
    "                  'treatment_icm_grouped', 'replicate_biological_with_treat',\n",
    "                   'cell_class', 'condition',\n",
    "                   'img_height', 'img_width', \n",
    "                #    'mask_area',\n",
    "                   'num_blank_rows', 'num_blank_cols',\n",
    "#                    'intensity_mu', 'intensity_sigma', \n",
    "                   'perc_high', 'perc_low', 'fg_mean',\n",
    "                   'perc_high_image', 'perc_low_image'\n",
    "                   \n",
    "                  ] \n",
    "\n",
    "feats_oldyoung = df_oldyoung.drop(columns=columns_to_drop).values\n",
    "feats_treated = df_treated.drop(columns=columns_to_drop).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2120a47-20b6-4360-9e7a-764b72230569",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_oldyoung = LabelEncoder()\n",
    "y_oldyoung = le_oldyoung.fit_transform(df_oldyoung.cell_class)\n",
    "\n",
    "X_oldyoung = SimpleImputer().fit_transform(feats_oldyoung)\n",
    "X_treated = SimpleImputer().fit_transform(feats_treated)\n",
    "\n",
    "# fit scaler on old/young samples and apply the same scaling to treated samples\n",
    "scaler = StandardScaler()\n",
    "X_oldyoung = scaler.fit_transform(X_oldyoung)\n",
    "X_treated = scaler.transform(X_treated)\n",
    "\n",
    "# the label encoder might switch old/young order, get indices\n",
    "young_old_indices = le_oldyoung.transform(oldyoung_classes)\n",
    "\n",
    "## randomly undersample the young images to match size of old\n",
    "## did not change classifier preference for 'young' much\n",
    "# X_oldyoung, y_oldyoung = RandomUnderSampler().fit_resample(X_oldyoung, y_oldyoung)\n",
    "# np.unique(y_oldyoung, return_counts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8690ccc-e4fc-4dd5-b26d-f8ebef489097",
   "metadata": {},
   "source": [
    "# 2) fit classifier on old & young"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dac1b8-e73a-4448-a7c7-7436e13fb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC with higher regularization than default (C parameter<1)\n",
    "cls = SVC(C=0.1, probability=True, class_weight='balanced')\n",
    "\n",
    "# CV scoring to assess classifier performance on old/young\n",
    "cv = StratifiedKFold(5, shuffle=True)\n",
    "y_oldyoung_pred = cross_val_predict(cls, X_oldyoung, y_oldyoung, n_jobs=-1, cv=cv)\n",
    "np.mean(y_oldyoung_pred == y_oldyoung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae7d54-2cb2-4f9c-a0be-22d323bc5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit again on whole old/young dataset\n",
    "cls.fit(X_oldyoung, y_oldyoung);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9de376f7-9a4e-447f-8695-eb4de25c5e64",
   "metadata": {},
   "source": [
    "# 3) apply to ICM treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d5a4f-831d-4849-9188-e83434202e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treated_pred = cls.predict_proba(X_treated)\n",
    "\n",
    "df_pred = pd.DataFrame()\n",
    "\n",
    "df_pred['cell_class'] = df_treated.treatment\n",
    "df_pred['replicate_bio'] = df_treated.replicate_biological\n",
    "df_pred['replicate_tech'] = df_treated.replicate_technical\n",
    "\n",
    "df_pred['prob_young'] = y_treated_pred.T[young_old_indices[0]]\n",
    "df_pred['prob_old'] = y_treated_pred.T[young_old_indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff4af0-4e41-4567-89bc-11f07a396331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "## group by technical or biological replicates\n",
    "# df_grouped = df_pred.groupby(['cell_class', 'replicate_tech'])[['prob_young', 'prob_old']]\n",
    "df_grouped = df_pred.groupby(['cell_class', 'replicate_bio'])[['prob_young', 'prob_old']]\n",
    "\n",
    "# average prediction per group\n",
    "df_confmat = df_grouped.mean()\n",
    "\n",
    "# add replicate size to index -> for labelling in plot\n",
    "df_confmat['count'] = list(map(lambda c: f'N={c}', df_grouped.count().iloc[:,0].values))\n",
    "df_confmat = df_confmat.set_index('count', append=True)\n",
    "\n",
    "plt.figure(figsize=(6,8))\n",
    "sns.heatmap(df_confmat, cmap='Blues', annot=True, vmin=0, vmax=1)\n",
    "plt.yticks(ticks=range(len(df_confmat)), labels=map(', '.join, df_confmat.index))\n",
    "plt.xticks(ticks=range(len(oldyoung_classes)), labels=['young', 'old'], rotation='vertical');\n",
    "\n",
    "# save\n",
    "plt.rc('pdf', fonttype='42')\n",
    "plt.savefig('/home/hoerl/ageing_dna_texture_figure_parts/confusionmatrix_oldyoung-classification_sted.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
